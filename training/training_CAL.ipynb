{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# standard imports \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from ipdb import set_trace\n",
    "\n",
    "# jupyter setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own modules\n",
    "from dataloader import CAL_Dataset\n",
    "from net import get_model\n",
    "from dataloader import get_data, get_mini_data\n",
    "from train import fit, custom_loss, validate\n",
    "from metrics import calc_metrics\n",
    "\n",
    "# paths\n",
    "data_path = './dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncomment the cell below if you want your experiments to yield always the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# manualSeed = 42\n",
    "\n",
    "# np.random.seed(manualSeed)\n",
    "# torch.manual_seed(manualSeed)\n",
    "\n",
    "# # if you are using GPU\n",
    "# torch.cuda.manual_seed(manualSeed)\n",
    "# torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "# torch.backends.cudnn.enabled = False \n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Possible Values for the task block type: MLP, LSTM, GRU, TempConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'name': 'test', 'type_': 'MLP', 'lr': 3e-4, 'n_h': 128, 'p':0.5, 'seq_len':1}\n",
    "model, opt = get_model(params)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the data loader. get mini data gets only a subset of the training data, on which we can try if the model is able to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_data(data_path, model.params.seq_len, batch_size=16)\n",
    "# train_dl, valid_dl = get_mini_data(data_path, model.params.seq_len, batch_size=16, l=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncomment the next cell if the feature extractor should also be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name,param in model.named_parameters():\n",
    "#     param.requires_grad = True\n",
    "# opt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. We automatically save the model with the lowest val_loss. If you want to continue the training and keep the loss history, just pass it as an additional argument as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, val_hist = fit(1, model, custom_loss, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model, val_hist = fit(1, model, custom_loss, opt, train_dl, valid_dl, val_hist=val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(val_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = get_model(params)\n",
    "model.load_state_dict(torch.load(f\"./models/{model.params.name}.pth\"))\n",
    "model.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval();\n",
    "_, all_preds, all_labels = validate(model, valid_dl, custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metrics(all_preds, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convience, we can pass an integer instead of the full string\n",
    "int2key = {0: 'red_light', 1:'hazard_stop', 2:'speed_sign', \n",
    "           3:'relative_angle', 4: 'center_distance', 5: 'veh_distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(k, all_preds, all_labels, start=0, delta=1000):\n",
    "    if isinstance(k, int): k = int2key[k]\n",
    "    \n",
    "    # get preds and labels\n",
    "    class_labels = ['red_light', 'hazard_stop', 'speed_sign']\n",
    "    pred = np.argmax(all_preds[k], axis=1) if k in class_labels else all_preds[k]\n",
    "    label = all_labels[k][:, 1] if k in class_labels else all_labels[k]\n",
    "    \n",
    "    plt.plot(pred[start:start+delta], 'r--', label='Prediction', linewidth=2.0)\n",
    "    plt.plot(label[start:start+delta], 'g', label='Ground Truth', linewidth=2.0)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preds(5, all_preds, all_labels, start=0, delta=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel2",
   "language": "python",
   "name": "mykernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
